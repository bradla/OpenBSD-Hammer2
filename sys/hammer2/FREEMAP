
			HAMMER2 Freemap Design Notes

				Overview

    HAMMER2 Media is broken down into 2 GByte zones.  Each 2 GByte zone
    contains a 4 MByte header (64 x 64K blocks).  The blocks in this header
    are reserved for various purposes.  For example, block #0 is used for
    the volume header or for a volume header backup.

    * It is very important to remember that the Freemap only uses blocks
      from these reserved areas.  Freemap blocks are NOT dynamically
      allocated.

    * On-mount, the synchronization TID for the main H2 filesystem is
      compared against the synchronization TID of the freemap and the
      H2 topology is incrementally iterated using mirror_tid to update
      the freemap with any missing information.  This way the freemap flush
      does not need to be synchronized with the normal H2 flush.  This
      can be done very quickly on-mount.

    * The freemap is flushed in a manner similar to the normal H2 filesystem,
      but as mentioned above it can be synchronized independently of the data
      it represents.  One freemap flush could cover several H2 flushes.  A
      freemap flush is not necessary for e.g. a fsync() or sync() to
      complete successfully.

    * The freemap granularity is 64KB (radix of 16) but the minimum
      allocation radix for code is 1KB (radix of 10).  1KB inodes can
      hold up to 512 bytes of direct data, so small files eat exactly
      1KB of media storage inclusive of the inode.

    * Representation of storage is block-oriented with ~1KB granularity
      in the filesystem topology.  However, H2 also stores freemap locality
      hints in the inode at all levels which specifies which freemap zones
      all storage allocations made by the sub-tree are allocated from.  Up
      to four zones may be listed in each inode.  The zones are power-of-2
      sized and aligned the same and use a base/radix representation
      (same as used for blockref->data_off).

      During updates higher level inodes may not have a sufficient number of
      entries to represent the storage used on a fine-grain.  In this
      situation the representations back-off to larger radix values.

      Ultimately these representations will be optimized by background scans.
      That is, ultimately storage localization can be optimized bottom-up
      such that it winds up being fairly optimal.  This includes the ability
      to detect when a writable snapshot has differentiated sufficiently to
      warrant a split.  This optimization should NOT attempt to dup common
      data blocks.

      XXX

    * The zone oriented forward storage references in the inode (the four
      entries) is used by the bulk free-scan to reduce the amount of
      meta-data which must be duplicatively scanned.  More specifically,
      when the sysadmin deletes storage and/or files or even whole directory
      subhierachies, it is possible for a bulk free-scan to incrementally
      scan the meta-data topology that covers ONLY those areas to determine
      if it is possible to free up any actual blocks.

      XXX

    * H2 does not require that a rm -rf or snapshot destruction, truncation,
      or any other operation actually mark freemap blocks as being
      almost-free.  That is, the freemap elements can remain set to
      ALLOCATED (11).  In fact, it is possible to just delete the directory
      inode itself and not even recursively scan or delete sub-directories or
      files.  The related storage will eventually be freed by an exhaustive
      bulk free-scan anyway.

				Freemap Topology

    The freemap topology contains 4 levels of meta-data (blockref arrays),
    one of which is embedded in the volume header (so only three real
    meta-data levels), plus one level of leaf-data.

    Level 1 - (radix 10) 64KB blockmap representing 2GB.  There are 1024
	      entries representing ~2MB worth of media storage per entry.

	      Each entry maps 32 x 64KB allocations @ 2 bits per allocation,
	      plus contains additional meta-data which allows H2 to cluster
	      I/O operations.  Each entry locks the allocation granularity
	      (e.g. to 1KB = radix 10 for inodes).

    Level 2 - (radix 10) 64KB blockmap representing 2TB (~2GB per entry)
    Level 3 - (radix 10) 64KB blockmap representing 2PB (~2TB per entry)
    Level 4 - (radix 10) 64KB blockmap representing 2EB (~2PB per entry)
    Level 5 - (radix 3) blockref x 8 in volume header representing 16EB (2^64)
	      (this conveniently eats one 512-byte 'sector' of the 64KB
	      volume header).

    Each level is assign reserved blocks in the 4MB header per 2GB zone.
    Since we use block 0 for the volume header / volume header backup,
    our level names above can simply also represent the relative block
    number.  Level 1 uses block 1 through level 4 using block 4.  Level 5
    is stored in the volume header.

    In addition there are FOUR SETS, A, B, C, and D, each containing blocks
    for level 1-4.  Hammer2 alternates between sets on a block-by-block basis
    in order to maintain consistency when updating the freemap.

				Leaf Substructure

    * radix  - Clustering radix.  All allocations for any given ~2MB zone
	       are always the same size, allowing the filesystem code to
	       cluster buffer cache I/O.

    * bitmap - four 32 bit words representing ~2MB in 64KB allocation chunks
	       at 2 bits per chunk.  The filesystem allocation granularity
	       can be smaller (currently ~1KB minimum), and the live
	       filesystem keeps caches iterations when allocating multiple
	       chunks.  However, on remount any partial allocations out of
	       a 64KB allocation block causes the entire 64KB to be
	       considered allocated.  Fragmented space can potentially be
	       reclaimed and/or relocated by the bulk block free scan.

	       The 2-bit bitmap fields are assigned as follows:

	       00	FREE
	       01	ARMED for free stage (future use)
	       10	ARMED for free stage (future use)
	       11	ALLOCATED

	       It should be noted that in some cases, such as snapshot
	       destruction, H2 does not bother to actually ARM the related
	       blocks (which would take a long time).  Instead, the bulk
	       free-scan may have to do a more exhaustive scan.

			      Blockref Substructure

    The blockref substructure at each level steals some space from the
    check code area (a 24-byte area).  We only need 4 bytes for the check
    code icrc.  We use some of the remaining space to store information
    that allows the block allocator to do its work more efficiently.

    * bigmask - A mask of radixes available for allocation under this
		blockref.  Typically initialized to -1.

    * avail   - Total available space in bytes.

    The freemap allocator uses a cylinder-group-like abstraction using
    the localized allocation concept first implemented by UFS.  In HAMMER2
    there is no such thing as a real cylinder group, but we do the next
    best thing by implementing our layer 1 blockmap representing 2GB.

    The layer 1 blockmap is an array of 1024 blockrefs, so each blockref
    covers 2MB worth of media storage.  HAMMER2's 'cylinder group' concept
    thus has a minimum granularity of 2MB.  A typical setting might be e.g.
    10MB.

    By localizing allocations to cylinder groups based on various bits of
    information, HAMMER2 tries to allocate space on the disk and still leave
    some left over for localized expansion and to reduce fragmentation at
    the same time.  Not an easy task, especially considering the copy-on-write
    nature of the filesystem.  This part of the algorithm likely needs a lot
    of work but I hope I've laid down a media format that will not have to be
    changed down the line to accomodate better allocation strategies.

			        Initial Conditions

    The freemap is a multi-indirect block structure but there is no real
    reason to pre-format it in newfs_hammer2.  Instead, newfs_hammer2 simply
    leaves the associated top-level indirect blocks empty and uses the
    (voldata->allocator_beg) field to allocate space linearly, then leaves
    it to the live filesystem to initialize the freemap as more space gets
    allocated.

				How blocks are freed

    The freemap bit patterns for each 64KB block are as follows:

       00	FREE
       01	ARMED (for free) (future use)
       10	ARMED (for free) (future use)
       11	ALLOCATED

    Currently H2 only implements 00 and 11.  When a file, topology, or
    snapshot is deleted H2 simply leaves the blocks marked allocated but
    records the related freezone/radix(s) in memory.

    At some point a background bulk free-scan will run.  This code must
    scan meta-data and has a limited cache to detect duplicative sub-trees
    (due to snapshots).  It uses the freezone/radix information recorded
    in memory to reduce the complexity of the scan, find all references to
    the related blocks in the meta-data, and determines what can actually
    be freed.  Once this determination is made the bulk free-scan sets
    the related freemap bits to FREE (00).

    An exhaustive free-scan is not usually required during normal operation
    but is typically run incrementally by cron every so often to ensure, over
    time, that all freeable blocks are actually freed.  This is most useful
    when maintaining multiple snapshots.

			Use of Generic indirect-block API

    I decided to use the same indirect-block allocation model for the
    freemap that normal files use, with a few special cases added to force
    specific radix values and to 'allocate' the freemap-related blocks
    and indirect blocks via a reserved-block calculation and (obviously)
    not via a recursive call to the allocator.

    The Freemap is defined above as a fixed 5-level scheme (level 1-5),
    but in actual operation the radix tree can be shortcut just as it
    is with normal files.  However, shorcuts are forced into the radix
    values of this specification and reserved blocks are calculated based
    on the radix level and offset, so as the freemap becomes more fleshed
    out the tree looks more and more like the specification.

    One advantage of doing things this way is that smaller filesystems
    won't actually use a 6-level scheme.  A 16GB filesystem can use 8
    blockrefs at layer 5 (in the volume header) that point directly to
    layer 1.  A 16TB filesystem can use 8 blockrefs at layer5 that point
    to layer 2.  And so forth.

    At the moment we have no plans to return any of the unused 4MB zone
    header space (per 2GB of storage) back to the filesystem for general use.
    There are lots of things we may want to use the reserved areas for in
    the future.
